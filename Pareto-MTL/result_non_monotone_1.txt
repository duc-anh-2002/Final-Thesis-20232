Reference vector (1/18): 0.9965845, 0.082579345
1/100: weights=[0.9941336  0.00586639], train_loss=[0.76785845 2.065479  ], train_acc=[0.74870833 0.28059167], test_loss=[0.75363266 2.0509505 ], test_acc=[0.7555 0.28  ]
2/100: weights=[0.995753   0.00424701], train_loss=[0.50507444 1.7394271 ], train_acc=[0.83709167 0.39050833], test_loss=[0.492754 1.723936], test_acc=[0.83745 0.3934 ]
Reference vector (1/18): 0.5, 0.5
1/100: weights=[0.8068693  0.19313066], train_loss=[2.3036792 2.3055203], train_acc=[0.11236667 0.110125  ], test_loss=[2.3034616 2.3044481], test_acc=[0.1135  0.11585]
2/100: weights=[0.34123892 0.6587611 ], train_loss=[2.3071737 2.3049138], train_acc=[0.10441667 0.110125  ], test_loss=[2.3081837 2.3034277], test_acc=[0.10285 0.11585]
4/100: weights=[0.50274163 0.4972584 ], train_loss=[2.3224127 2.3122895], train_acc=[0.0975   0.110125], test_loss=[2.3208983 2.3096962], test_acc=[0.0974  0.11585]
6/100: weights=[0.20836829 0.7916317 ], train_loss=[2.3101768 2.312119 ], train_acc=[0.09736667 0.10156667], test_loss=[2.3106215 2.3150125], test_acc=[0.0982  0.09765]
8/100: weights=[0.49743393 0.5025661 ], train_loss=[2.3104365 2.311406 ], train_acc=[0.098725   0.10156667], test_loss=[2.310698  2.3121395], test_acc=[0.098   0.09765]
10/100: weights=[0.44485205 0.55514795], train_loss=[2.32736   2.3090057], train_acc=[0.09736667 0.110125  ], test_loss=[2.3273668 2.3079283], test_acc=[0.0982  0.11585]
12/100: weights=[0.56597984 0.43402016], train_loss=[2.322791  2.3142076], train_acc=[0.09736667 0.09799167], test_loss=[2.32084   2.3137825], test_acc=[0.0982  0.09675]
14/100: weights=[0.50827384 0.49172616], train_loss=[2.3081627 2.308676 ], train_acc=[0.10441667 0.1002    ], test_loss=[2.3091786 2.3072646], test_acc=[0.10285 0.10135]
16/100: weights=[0.37266737 0.6273326 ], train_loss=[2.3153648 2.312204 ], train_acc=[0.09915 0.0994 ], test_loss=[2.3162565 2.3125627], test_acc=[0.1009 0.0958]
18/100: weights=[0.44372666 0.55627334], train_loss=[2.30741   2.3086886], train_acc=[0.09736667 0.0994    ], test_loss=[2.307477  2.3096967], test_acc=[0.0982 0.0958]
20/100: weights=[0.3677097 0.6322903], train_loss=[2.3145597 2.3147275], train_acc=[0.10441667 0.09799167], test_loss=[2.3154252 2.314627 ], test_acc=[0.10285 0.09675]
22/100: weights=[0.5593442  0.44065583], train_loss=[2.3079233 2.3127139], train_acc=[0.11236667 0.1002    ], test_loss=[2.3063338 2.3124444], test_acc=[0.1135  0.10135]
24/100: weights=[0.38978407 0.6102159 ], train_loss=[2.3195546 2.3087015], train_acc=[0.10441667 0.110125  ], test_loss=[2.3215063 2.3071833], test_acc=[0.10285 0.11585]
26/100: weights=[0.6531099  0.34689012], train_loss=[2.3057969 2.3106723], train_acc=[0.10441667 0.10156667], test_loss=[2.307129 2.310399], test_acc=[0.10285 0.09765]
28/100: weights=[0.4162512 0.5837488], train_loss=[2.3045928 2.308914 ], train_acc=[0.11236667 0.096575  ], test_loss=[2.3040392 2.309978 ], test_acc=[0.1135  0.09475]
30/100: weights=[0.2733533  0.72664666], train_loss=[2.3133395 2.3171523], train_acc=[0.10441667 0.09094167], test_loss=[2.313418  2.3151243], test_acc=[0.10285 0.0895 ]
32/100: weights=[0.8224081  0.17759189], train_loss=[2.3109274 2.3091772], train_acc=[0.09736667 0.096575  ], test_loss=[2.3098636 2.308772 ], test_acc=[0.0982  0.09475]
34/100: weights=[0.28986824 0.71013176], train_loss=[2.3043747 2.3100486], train_acc=[0.10441667 0.09799167], test_loss=[2.304467 2.309376], test_acc=[0.10285 0.09675]
36/100: weights=[0.67959493 0.32040504], train_loss=[2.3098695 2.3151922], train_acc=[0.10218333 0.0994    ], test_loss=[2.3095877 2.3175216], test_acc=[0.101  0.0958]
38/100: weights=[0.46082887 0.53917116], train_loss=[2.318076  2.3150408], train_acc=[0.09863333 0.10156667], test_loss=[2.3194191 2.315981 ], test_acc=[0.0957  0.09765]
40/100: weights=[0.66455746 0.33544254], train_loss=[2.315018  2.3131638], train_acc=[0.10218333 0.10083333], test_loss=[2.3164232 2.3114734], test_acc=[0.101  0.1022]
42/100: weights=[0.60181916 0.39818084], train_loss=[2.3190508 2.3330574], train_acc=[0.09915    0.09799167], test_loss=[2.3195963 2.3317199], test_acc=[0.1009  0.09675]
44/100: weights=[0.72992456 0.2700754 ], train_loss=[2.3130472 2.3187006], train_acc=[0.10441667 0.10156667], test_loss=[2.3138423 2.3203602], test_acc=[0.10285 0.09765]
46/100: weights=[0.54555184 0.45444816], train_loss=[2.3167894 2.306751 ], train_acc=[0.0993 0.1002], test_loss=[2.3155594 2.3057513], test_acc=[0.10325 0.10135]
48/100: weights=[0.820844   0.17915599], train_loss=[2.3088129 2.3235126], train_acc=[0.0993   0.104275], test_loss=[2.3075218 2.320335 ], test_acc=[0.10325 0.10485]
50/100: weights=[0.703211 0.296789], train_loss=[2.330797  2.3136868], train_acc=[0.11236667 0.09799167], test_loss=[2.329153  2.3109026], test_acc=[0.1135  0.09675]
52/100: weights=[0.4472211 0.5527789], train_loss=[2.3240366 2.315814 ], train_acc=[0.0993   0.096575], test_loss=[2.3217304 2.3151128], test_acc=[0.10325 0.09475]
54/100: weights=[0.5581645 0.4418355], train_loss=[2.3059363 2.3107383], train_acc=[0.0993     0.09799167], test_loss=[2.3046324 2.3100157], test_acc=[0.10325 0.09675]
56/100: weights=[0.68338233 0.31661767], train_loss=[2.3088095 2.3110852], train_acc=[0.10218333 0.1002    ], test_loss=[2.3079903 2.3103802], test_acc=[0.101   0.10135]
58/100: weights=[0.5219232 0.4780768], train_loss=[2.3077784 2.3059187], train_acc=[0.09736667 0.09809167], test_loss=[2.307489  2.3056397], test_acc=[0.0982 0.1013]
60/100: weights=[0.56646097 0.433539  ], train_loss=[2.307372  2.3130972], train_acc=[0.11236667 0.104275  ], test_loss=[2.3057497 2.3109941], test_acc=[0.1135  0.10485]
62/100: weights=[0.30846095 0.69153905], train_loss=[2.3227882 2.3206513], train_acc=[0.098725 0.110125], test_loss=[2.3225756 2.31478  ], test_acc=[0.098   0.11585]
64/100: weights=[0.4630502 0.5369498], train_loss=[2.3085177 2.3082309], train_acc=[0.0975   0.110125], test_loss=[2.3085895 2.308742 ], test_acc=[0.0974  0.11585]
66/100: weights=[0.574832   0.42516795], train_loss=[2.306233 2.312304], train_acc=[0.098725   0.10156667], test_loss=[2.3057215 2.3143396], test_acc=[0.098   0.09765]
68/100: weights=[0.5203039  0.47969612], train_loss=[2.303224  2.3070035], train_acc=[0.11236667 0.10083333], test_loss=[2.3027673 2.3057892], test_acc=[0.1135 0.1022]
70/100: weights=[0.3677059  0.63229406], train_loss=[2.3038692 2.303972 ], train_acc=[0.09863333 0.110125  ], test_loss=[2.3043566 2.3028708], test_acc=[0.0957  0.11585]
72/100: weights=[0.477783 0.522217], train_loss=[2.30284  2.306827], train_acc=[0.11236667 0.1002    ], test_loss=[2.3031263 2.307639 ], test_acc=[0.1135  0.10135]
74/100: weights=[0.39645743 0.60354257], train_loss=[2.3021798 2.31191  ], train_acc=[0.10441667 0.096575  ], test_loss=[2.3024828 2.3101256], test_acc=[0.10285 0.09475]
76/100: weights=[0.3502244 0.6497756], train_loss=[2.3211932 2.309708 ], train_acc=[0.09863333 0.1002    ], test_loss=[2.322912  2.3092065], test_acc=[0.0957  0.10135]
78/100: weights=[0.25013512 0.7498649 ], train_loss=[2.315986  2.3038719], train_acc=[0.0975 0.0994], test_loss=[2.3171124 2.3034823], test_acc=[0.0974 0.0958]
80/100: weights=[0.38553903 0.614461  ], train_loss=[2.3040442 2.309199 ], train_acc=[0.0975   0.110125], test_loss=[2.3041573 2.3061144], test_acc=[0.0974  0.11585]
82/100: weights=[0.40221947 0.5977805 ], train_loss=[2.31699   2.3108804], train_acc=[0.11236667 0.096575  ], test_loss=[2.316408  2.3104265], test_acc=[0.1135  0.09475]
84/100: weights=[0.60588384 0.39411616], train_loss=[2.305487 2.303542], train_acc=[0.11236667 0.1002    ], test_loss=[2.3050396 2.304104 ], test_acc=[0.1135  0.10135]
86/100: weights=[0.22351632 0.7764837 ], train_loss=[2.3108451 2.3050036], train_acc=[0.09915  0.104275], test_loss=[2.3113406 2.3047955], test_acc=[0.1009  0.10485]
88/100: weights=[0.41051406 0.58948594], train_loss=[2.307004  2.3040142], train_acc=[0.09915 0.1002 ], test_loss=[2.3055184 2.3040867], test_acc=[0.1009  0.10135]
90/100: weights=[0.52135575 0.47864422], train_loss=[2.323678  2.3142908], train_acc=[0.09915  0.110125], test_loss=[2.3230379 2.3107562], test_acc=[0.1009  0.11585]
92/100: weights=[0.49242917 0.5075708 ], train_loss=[2.3036063 2.3063638], train_acc=[0.11236667 0.110125  ], test_loss=[2.3028772 2.305134 ], test_acc=[0.1135  0.11585]
94/100: weights=[0.49134693 0.50865304], train_loss=[2.312011  2.3042834], train_acc=[0.11236667 0.10083333], test_loss=[2.310861  2.3030438], test_acc=[0.1135 0.1022]
96/100: weights=[0.4997479 0.5002521], train_loss=[2.319762  2.3103085], train_acc=[0.09863333 0.110125  ], test_loss=[2.3211143 2.3086789], test_acc=[0.0957  0.11585]
98/100: weights=[0.32382298 0.676177  ], train_loss=[2.3056202 2.3058903], train_acc=[0.11236667 0.104275  ], test_loss=[2.3045254 2.3045547], test_acc=[0.1135  0.10485]
100/100: weights=[0.6774796  0.32252038], train_loss=[2.31044  2.313365], train_acc=[0.11236667 0.09809167], test_loss=[2.3106084 2.311963 ], test_acc=[0.1135 0.1013]
Reference vector (2/18): 0.5, 0.5
1/100: weights=[0.44469056 0.5553094 ], train_loss=[0.655001  0.7741339], train_acc=[0.786375 0.73695 ], test_loss=[0.6419279 0.7678812], test_acc=[0.7893  0.74205]
