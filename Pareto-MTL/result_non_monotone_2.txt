Reference vector (1/18): 0.9965845, 0.082579345
1/100: weights=[1.9677039  0.03229612], train_loss=[1.4283335 2.662974 ], train_acc=[0.52441667 0.12611667], test_loss=[1.4064096 2.671639 ], test_acc=[0.53185 0.1229 ]
2/100: weights=[1.9981856e+00 1.8143698e-03], train_loss=[2.3021138 4.9313474], train_acc=[0.11236667 0.10156667], test_loss=[2.3021746 4.9011445], test_acc=[0.1135  0.09765]
4/100: weights=[1.996756   0.00324399], train_loss=[2.3016665 2.3016226], train_acc=[0.11236667 0.110125  ], test_loss=[2.3013492 2.301016 ], test_acc=[0.1135  0.11585]
6/100: weights=[1.9855187  0.01448136], train_loss=[2.3018494 2.3017907], train_acc=[0.11236667 0.110125  ], test_loss=[2.3023517 2.3008776], test_acc=[0.1135  0.11585]
8/100: weights=[1.9941784  0.00582154], train_loss=[2.301771 2.301796], train_acc=[0.11236667 0.110125  ], test_loss=[2.3015444 2.3010607], test_acc=[0.1135  0.11585]
10/100: weights=[1.9926022  0.00739783], train_loss=[2.3013723 2.3015692], train_acc=[0.11236667 0.110125  ], test_loss=[2.301168  2.3008225], test_acc=[0.1135  0.11585]
12/100: weights=[1.9848977  0.01510228], train_loss=[2.3019993 2.30153  ], train_acc=[0.10441667 0.110125  ], test_loss=[2.3022997 2.3007648], test_acc=[0.10285 0.11585]
14/100: weights=[1.9976265  0.00237341], train_loss=[2.3016636 2.3014743], train_acc=[0.11236667 0.110125  ], test_loss=[2.3016582 2.3007433], test_acc=[0.1135  0.11585]
16/100: weights=[1.9962367  0.00376336], train_loss=[2.3016245 2.3016057], train_acc=[0.11236667 0.110125  ], test_loss=[2.301012  2.3007965], test_acc=[0.1135  0.11585]
18/100: weights=[1.9879817  0.01201836], train_loss=[2.301736  2.3028424], train_acc=[0.11236667 0.110125  ], test_loss=[2.3013816 2.3019352], test_acc=[0.1135  0.11585]
20/100: weights=[1.998 0.002], train_loss=[2.3013608 2.3015137], train_acc=[0.11236667 0.110125  ], test_loss=[2.3012793 2.3009214], test_acc=[0.1135  0.11585]
22/100: weights=[1.998 0.002], train_loss=[2.3018792 2.3015392], train_acc=[0.10441667 0.110125  ], test_loss=[2.3016794 2.3007493], test_acc=[0.10285 0.11585]
24/100: weights=[1.993943   0.00605701], train_loss=[2.3013856 2.3014958], train_acc=[0.11236667 0.110125  ], test_loss=[2.301171  2.3008432], test_acc=[0.1135  0.11585]
26/100: weights=[1.998 0.002], train_loss=[2.3022487 2.3014944], train_acc=[0.10218333 0.110125  ], test_loss=[2.3026288 2.3008316], test_acc=[0.101   0.11585]
28/100: weights=[1.9961733  0.00382678], train_loss=[2.3018749 2.301507 ], train_acc=[0.11236667 0.110125  ], test_loss=[2.3017492 2.3008385], test_acc=[0.1135  0.11585]
30/100: weights=[1.998 0.002], train_loss=[2.3014612 2.3015523], train_acc=[0.11236667 0.110125  ], test_loss=[2.301285  2.3008254], test_acc=[0.1135  0.11585]
32/100: weights=[1.9990157e+00 9.8432798e-04], train_loss=[2.301474  2.3016663], train_acc=[0.11236667 0.110125  ], test_loss=[2.3011456 2.300913 ], test_acc=[0.1135  0.11585]
34/100: weights=[1.992445   0.00755504], train_loss=[2.301442 2.301536], train_acc=[0.11236667 0.110125  ], test_loss=[2.3014588 2.3007884], test_acc=[0.1135  0.11585]
36/100: weights=[1.998 0.002], train_loss=[2.3018756 2.3015027], train_acc=[0.11236667 0.110125  ], test_loss=[2.3019974 2.3007996], test_acc=[0.1135  0.11585]
38/100: weights=[1.9991463e+00 8.5367035e-04], train_loss=[2.3012924 2.3016548], train_acc=[0.11236667 0.110125  ], test_loss=[2.3011565 2.3009524], test_acc=[0.1135  0.11585]
40/100: weights=[1.9747312  0.02526876], train_loss=[2.3015044 2.3014913], train_acc=[0.11236667 0.110125  ], test_loss=[2.3013072 2.3007488], test_acc=[0.1135  0.11585]
42/100: weights=[1.9988116e+00 1.1883763e-03], train_loss=[2.301456  2.3016157], train_acc=[0.11236667 0.110125  ], test_loss=[2.301147  2.3007078], test_acc=[0.1135  0.11585]
44/100: weights=[1.998 0.002], train_loss=[2.3017719 2.3015957], train_acc=[0.10441667 0.110125  ], test_loss=[2.301913  2.3010185], test_acc=[0.10285 0.11585]
46/100: weights=[1.9982607e+00 1.7392754e-03], train_loss=[2.3012705 2.3015187], train_acc=[0.11236667 0.110125  ], test_loss=[2.301109  2.3008964], test_acc=[0.1135  0.11585]
48/100: weights=[1.9896739  0.01032619], train_loss=[2.3013992 2.3017538], train_acc=[0.11236667 0.110125  ], test_loss=[2.301192 2.300926], test_acc=[0.1135  0.11585]
50/100: weights=[1.9962872  0.00371282], train_loss=[2.3014317 2.3015149], train_acc=[0.11236667 0.110125  ], test_loss=[2.3011081 2.3007967], test_acc=[0.1135  0.11585]
52/100: weights=[1.9901028  0.00989722], train_loss=[2.301695  2.3015618], train_acc=[0.11236667 0.110125  ], test_loss=[2.3017464 2.3007112], test_acc=[0.1135  0.11585]
54/100: weights=[1.9966086  0.00339135], train_loss=[2.3013563 2.3014877], train_acc=[0.11236667 0.110125  ], test_loss=[2.3010814 2.300788 ], test_acc=[0.1135  0.11585]
56/100: weights=[1.9895957  0.01040438], train_loss=[2.301379  2.3016143], train_acc=[0.11236667 0.110125  ], test_loss=[2.301209 2.300788], test_acc=[0.1135  0.11585]
58/100: weights=[1.969876   0.03012392], train_loss=[2.3015506 2.30154  ], train_acc=[0.11236667 0.110125  ], test_loss=[2.301348  2.3009193], test_acc=[0.1135  0.11585]
60/100: weights=[1.998 0.002], train_loss=[2.301445  2.3015044], train_acc=[0.11236667 0.110125  ], test_loss=[2.3010507 2.3008578], test_acc=[0.1135  0.11585]
62/100: weights=[1.9919276  0.00807242], train_loss=[2.3013275 2.301527 ], train_acc=[0.11236667 0.110125  ], test_loss=[2.3011935 2.3008735], test_acc=[0.1135  0.11585]
64/100: weights=[1.9950768  0.00492322], train_loss=[2.3014815 2.301508 ], train_acc=[0.11236667 0.110125  ], test_loss=[2.301434  2.3007083], test_acc=[0.1135  0.11585]
66/100: weights=[1.9812877  0.01871234], train_loss=[2.3013768 2.3016582], train_acc=[0.11236667 0.110125  ], test_loss=[2.3012166 2.3009338], test_acc=[0.1135  0.11585]
68/100: weights=[1.998 0.002], train_loss=[2.301442  2.3017673], train_acc=[0.11236667 0.110125  ], test_loss=[2.3010714 2.300902 ], test_acc=[0.1135  0.11585]
70/100: weights=[1.9993802e+00 6.1977893e-04], train_loss=[2.3013227 2.3015962], train_acc=[0.11236667 0.110125  ], test_loss=[2.3011568 2.3008163], test_acc=[0.1135  0.11585]
72/100: weights=[1.998 0.002], train_loss=[2.3014908 2.3015273], train_acc=[0.11236667 0.110125  ], test_loss=[2.3016071 2.30088  ], test_acc=[0.1135  0.11585]
74/100: weights=[1.998 0.002], train_loss=[2.3014333 2.3015559], train_acc=[0.11236667 0.110125  ], test_loss=[2.3011847 2.3008103], test_acc=[0.1135  0.11585]
76/100: weights=[1.998 0.002], train_loss=[2.301495  2.3014836], train_acc=[0.11236667 0.110125  ], test_loss=[2.3015766 2.3008008], test_acc=[0.1135  0.11585]
78/100: weights=[1.998 0.002], train_loss=[2.301371 2.3019  ], train_acc=[0.11236667 0.110125  ], test_loss=[2.3012366 2.3011758], test_acc=[0.1135  0.11585]
80/100: weights=[1.9790967  0.02090333], train_loss=[2.3013086 2.301548 ], train_acc=[0.11236667 0.110125  ], test_loss=[2.30125   2.3009565], test_acc=[0.1135  0.11585]
82/100: weights=[1.998 0.002], train_loss=[2.301287  2.3017979], train_acc=[0.11236667 0.110125  ], test_loss=[2.3011286 2.3009548], test_acc=[0.1135  0.11585]
84/100: weights=[1.998 0.002], train_loss=[2.3014925 2.301901 ], train_acc=[0.11236667 0.104275  ], test_loss=[2.3013914 2.3014467], test_acc=[0.1135  0.10485]
86/100: weights=[1.9973854  0.00261458], train_loss=[2.3014686 2.3014781], train_acc=[0.11236667 0.110125  ], test_loss=[2.3016   2.300806], test_acc=[0.1135  0.11585]
88/100: weights=[1.998 0.002], train_loss=[2.30134   2.3014803], train_acc=[0.11236667 0.110125  ], test_loss=[2.3013077 2.3008952], test_acc=[0.1135  0.11585]
90/100: weights=[1.9908923  0.00910774], train_loss=[2.301278  2.3015285], train_acc=[0.11236667 0.110125  ], test_loss=[2.3012197 2.300955 ], test_acc=[0.1135  0.11585]
92/100: weights=[1.9998096e+00 1.9039062e-04], train_loss=[2.3015199 2.301525 ], train_acc=[0.11236667 0.110125  ], test_loss=[2.301594  2.3007584], test_acc=[0.1135  0.11585]
94/100: weights=[1.9994205e+00 5.7948707e-04], train_loss=[2.3013177 2.301618 ], train_acc=[0.11236667 0.110125  ], test_loss=[2.3012805 2.300726 ], test_acc=[0.1135  0.11585]
96/100: weights=[1.9713657  0.02863429], train_loss=[2.301217  2.3015978], train_acc=[0.11236667 0.110125  ], test_loss=[2.301067 2.300755], test_acc=[0.1135  0.11585]
98/100: weights=[1.998 0.002], train_loss=[2.301447 2.302128], train_acc=[0.11236667 0.104275  ], test_loss=[2.301493  2.3017042], test_acc=[0.1135  0.10485]
100/100: weights=[1.9971836  0.00281641], train_loss=[2.3012304 2.3015537], train_acc=[0.11236667 0.110125  ], test_loss=[2.3011127 2.3010507], test_acc=[0.1135  0.11585]
Reference vector (2/18): 0.9863613, 0.16459459
1/100: weights=[1.9437052 0.0562948], train_loss=[2.0176528 2.4490929], train_acc=[0.29965    0.12275833], test_loss=[2.0077324 2.4488647], test_acc=[0.3086  0.12155]
